parameters:
- name: timeout
  type: number
  default: 480

- name: log_artifact_name
  type: string

- name: gcov_artifact_name
  type: string

- name: sonic_slave
  type: string

- name: archive_gcov
  type: boolean
  default: false

jobs:
- job:
  displayName: vstest
  timeoutInMinutes: ${{ parameters.timeout }}

  pool: sonic-common

  steps:
  - script: |
      ls -A1 | xargs -I{} sudo rm -rf {}
    displayName: "Clean workspace"
  - checkout: self
  - task: DownloadPipelineArtifact@2
    inputs:
      artifact: docker-sonic-vs
      path: $(Build.ArtifactStagingDirectory)/download
    displayName: "Download pre-stage built docker-sonic-vs"
  - task: DownloadPipelineArtifact@2
    inputs:
      source: specific
      project: build
      pipeline: Azure.sonic-swss-common
      artifact: sonic-swss-common.amd64.ubuntu20_04
      runVersion: 'latestFromBranch'
      runBranch: 'refs/heads/$(BUILD_BRANCH)'
      path: $(Build.ArtifactStagingDirectory)/download
    displayName: "Download sonic swss common deb packages"

  - script: |
      set -ex
      sudo .azure-pipelines/build_and_install_module.sh

      sudo apt-get install -y libhiredis0.14
      sudo dpkg -i --force-confask,confnew $(Build.ArtifactStagingDirectory)/download/libswsscommon_1.0.0_amd64.deb || apt-get install -f
      sudo dpkg -i $(Build.ArtifactStagingDirectory)/download/python3-swsscommon_1.0.0_amd64.deb

      # install packages for vs test
      sudo apt-get install -y net-tools bridge-utils vlan
      sudo apt-get install -y python3-pip
      sudo pip3 install pytest==4.6.2 attrs==19.1.0 exabgp==4.0.10 distro==1.5.0 docker==4.4.1 redis==3.3.4 flaky==3.7.0
    displayName: "Install dependencies"

  - script: |
      set -ex
      sudo docker load -i $(Build.ArtifactStagingDirectory)/download/docker-sonic-vs.gz
      docker ps
      ip netns list
      uname -a
      sudo /sbin/ip link add Vrf1 type vrf table 1001 || { echo 'vrf command failed' ; exit 1; }
      sudo /sbin/ip link del Vrf1 type vrf table 1001
      pushd tests

      if [ '${{ parameters.archive_gcov }}' == True ]; then
        all_tests=$(ls test_*.py)
        all_tests="${all_tests} p4rt"
        for test in ${all_tests}; do
          test_name=$(echo "${test}" | cut -d "." -f 1)
          sudo py.test -v --force-flaky --junitxml="${test_name}_tr.xml" --keeptb --imgname=docker-sonic-vs:$(Build.DefinitionName).$(Build.BuildNumber) ${test}
          container_count=$(docker ps -q -a | wc -l)
          if [ ${container_count} -gt 0 ]; then
            ./gcov_support.sh set_environment $(Build.ArtifactStagingDirectory)
            docker stop $(docker ps -q -a)
            docker rm $(docker ps -q -a)
          fi
        done
      else
        sudo py.test -v --force-flaky --junitxml=tests_tr.xml --imgname=docker-sonic-vs:$(Build.DefinitionName).$(Build.BuildNumber)
      fi
      rm -rf $(Build.ArtifactStagingDirectory)/download
    displayName: "Run vs tests"

  - task: PublishTestResults@2
    inputs:
      testResultsFiles: '**/*_tr.xml'
      testRunTitle: vstest
    condition: always()

  - script: |
      cp -r tests/log $(Build.ArtifactStagingDirectory)/

      if [ '${{ parameters.archive_gcov }}' == True ]; then
        sudo apt-get install -y lcov
        cd $(Build.ArtifactStagingDirectory)/gcov_tmp/
        tar -zcvf sonic-gcov.tar.gz sonic-gcov/
        rm -rf sonic-gcov
      fi
    displayName: "Collect logs"
    condition: always()

  - publish: $(Build.ArtifactStagingDirectory)/gcov_tmp
    artifact: ${{ parameters.gcov_artifact_name }}
    displayName: "Publish gcov output"
    condition: and(succeeded(), eq('${{ parameters.archive_gcov }}', true))

  - publish: $(Build.ArtifactStagingDirectory)/
    artifact: ${{ parameters.log_artifact_name }}@$(System.JobAttempt)
    displayName: "Publish logs"
    condition: always()
